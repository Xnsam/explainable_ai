{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XAI_basics",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhzdS5QBF-CB"
      },
      "source": [
        "# SHAP Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F8mKH7yHHYf"
      },
      "source": [
        "!pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ynoPNnRE5-P"
      },
      "source": [
        "import keras\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import numpy as np\n",
        "import shap\n",
        "# import keras.backend as K\n",
        "import json\n",
        "\n",
        "shap.initjs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLL-RghOZOON"
      },
      "source": [
        "import tensorflow.compat.v1.keras.backend as K\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Uw3oliHGGa"
      },
      "source": [
        "def visualize_model_decisions(shap_values, x, labels=None, figsize=(20, 30)):\n",
        "    \n",
        "    colors = []\n",
        "    for l in np.linspace(1, 0, 100):\n",
        "        colors.append((30./255, 136./255, 229./255,l))\n",
        "    for l in np.linspace(0, 1, 100):\n",
        "        colors.append((255./255, 13./255, 87./255,l))\n",
        "    red_transparent_blue = LinearSegmentedColormap.from_list(\"red_transparent_blue\", colors)\n",
        "\n",
        "    multi_output = True\n",
        "    if type(shap_values) != list:\n",
        "        multi_output = False\n",
        "        shap_values = [shap_values]\n",
        "\n",
        "    # make sure labels\n",
        "    if labels is not None:\n",
        "        assert labels.shape[0] == shap_values[0].shape[0], \"Labels must have same row count as shap_values arrays!\"\n",
        "        if multi_output:\n",
        "            assert labels.shape[1] == len(shap_values), \"Labels must have a column for each output in shap_values!\"\n",
        "        else:\n",
        "            assert len(labels.shape) == 1, \"Labels must be a vector for single output shap_values.\"\n",
        "\n",
        "    # plot our explanations\n",
        "    fig_size = figsize\n",
        "    fig, axes = plt.subplots(nrows=x.shape[0], ncols=len(shap_values) + 1, figsize=fig_size)\n",
        "    if len(axes.shape) == 1:\n",
        "        axes = axes.reshape(1,axes.size)\n",
        "    for row in range(x.shape[0]):\n",
        "        x_curr = x[row].copy()\n",
        "\n",
        "        # make sure\n",
        "        if len(x_curr.shape) == 3 and x_curr.shape[2] == 1:\n",
        "            x_curr = x_curr.reshape(x_curr.shape[:2])\n",
        "        if x_curr.max() > 1:\n",
        "            x_curr /= 255.\n",
        "        \n",
        "        axes[row,0].imshow(x_curr)\n",
        "        axes[row,0].axis('off')\n",
        "        \n",
        "        # get a grayscale version of the image\n",
        "        if len(x_curr.shape) == 3 and x_curr.shape[2] == 3:\n",
        "            x_curr_gray = (0.2989 * x_curr[:,:,0] + 0.5870 * x_curr[:,:,1] + 0.1140 * x_curr[:,:,2]) # rgb to gray\n",
        "        else:\n",
        "            x_curr_gray = x_curr\n",
        "\n",
        "        if len(shap_values[0][row].shape) == 2:\n",
        "            abs_vals = np.stack([np.abs(shap_values[i]) for i in range(len(shap_values))], 0).flatten()\n",
        "        else:\n",
        "            abs_vals = np.stack([np.abs(shap_values[i].sum(-1)) for i in range(len(shap_values))], 0).flatten()\n",
        "        max_val = np.nanpercentile(abs_vals, 99.9)\n",
        "        for i in range(len(shap_values)):\n",
        "            if labels is not None:\n",
        "                axes[row,i+1].set_title(labels[row,i])\n",
        "            sv = shap_values[i][row] if len(shap_values[i][row].shape) == 2 else shap_values[i][row].sum(-1)\n",
        "            axes[row,i+1].imshow(x_curr_gray, cmap=plt.get_cmap('gray'), alpha=0.15, extent=(-1, sv.shape[0], sv.shape[1], -1))\n",
        "            im = axes[row,i+1].imshow(sv, cmap=red_transparent_blue, vmin=-max_val, vmax=max_val)\n",
        "            axes[row,i+1].axis('off')\n",
        "        \n",
        "    cb = fig.colorbar(im, ax=np.ravel(axes).tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=fig_size[0]/0.2)\n",
        "    cb.outline.set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4fUIEw-SUcX"
      },
      "source": [
        "model = VGG16(weights=\"imagenet\", include_top=True)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TznX12JSlbW"
      },
      "source": [
        "X, y = shap.datasets.imagenet50()\n",
        "len(X), len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSMk2MFsT2Du"
      },
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://images.unsplash.com/photo-1529778873920-4da4926a72c2?ixid=MnwxMjA3fDB8MHxzZWFyY2h8MXx8Y3V0ZSUyMGNhdHxlbnwwfHwwfHw%3D&ixlib=rb-1.2.1&w=1000&q=80\"\n",
        "resp = requests.get(url)\n",
        "\n",
        "with open('cat.png', 'wb') as f:\n",
        "  f.write(resp.content)\n",
        "\n",
        "img_path = 'cat.png'\n",
        "img = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERA5pKtTTKyV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "to_predict = np.array([X[28], X[35], X[46], img])\n",
        "fig, ax = plt.subplots(1, 4, figsize=(18, 10))\n",
        "ax[0].imshow(to_predict[0]/255)\n",
        "ax[1].imshow(to_predict[1]/255)\n",
        "ax[2].imshow(to_predict[2]/255)\n",
        "ax[3].imshow(to_predict[3]/255)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWC7XXPJU2Kt"
      },
      "source": [
        "\n",
        "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
        "fname = shap.datasets.cache(url)\n",
        "with open(fname) as f:\n",
        "    class_names = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz0Tm7U8VGu9"
      },
      "source": [
        "predictions = model.predict(preprocess_input(to_predict.copy()))\n",
        "predictions, predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQWHN4jEVSRV"
      },
      "source": [
        "predicted_labels = [class_names.get(str(pred)) for pred in np.argmax(predictions, axis=1)]\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeAE6S_ZVib9"
      },
      "source": [
        "def map2layer(x, layer):\n",
        "    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n",
        "    return K.get_session().run(model.layers[layer].input, feed_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9wUxAxaWHGF"
      },
      "source": [
        "e = shap.GradientExplainer((model.layers[7].input, model.layers[-1].output), \n",
        "                            map2layer(preprocess_input(X.copy()), 7))\n",
        "shap_values, indexes = e.shap_values(map2layer(to_predict, 7), ranked_outputs=1)\n",
        "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
        "index_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R78AHTsYbEt"
      },
      "source": [
        "visualize_model_decisions(shap_values=shap_values, x=to_predict, \n",
        "                          labels=index_names, figsize=(20, 40))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn0fq3KZau-F"
      },
      "source": [
        "e = shap.GradientExplainer((model.layers[14].input, model.layers[-1].output), \n",
        "                            map2layer(preprocess_input(X.copy()), 14))\n",
        "shap_values, indexes = e.shap_values(map2layer(to_predict, 14), ranked_outputs=1)\n",
        "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
        "index_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwY2wdqPh8Bq"
      },
      "source": [
        "visualize_model_decisions(shap_values=shap_values, x=to_predict, \n",
        "                          labels=index_names, figsize=(20, 40))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSesta1wv_ie"
      },
      "source": [
        "# TF Explain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSIaZtDbh82R"
      },
      "source": [
        "!pip install tf-explain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOAKeVCpwVU1"
      },
      "source": [
        "import tensorflow.compat.v1.keras.backend as K\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "import numpy as np\n",
        "# import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "from tf_explain.core.activations import ExtractActivations\n",
        "from tensorflow.keras.applications.xception import decode_predictions\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FG8URFnPsN-"
      },
      "source": [
        "model = tf.keras.applications.xception.Xception(weights='imagenet', include_top=True)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3TVjB83QBOW"
      },
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://images.unsplash.com/photo-1529778873920-4da4926a72c2?ixid=MnwxMjA3fDB8MHxzZWFyY2h8MXx8Y3V0ZSUyMGNhdHxlbnwwfHwwfHw%3D&ixlib=rb-1.2.1&w=1000&q=80\"\n",
        "resp = requests.get(url)\n",
        "\n",
        "with open('cat.png', 'wb') as f:\n",
        "  f.write(resp.content)\n",
        "\n",
        "img_path = 'cat.png'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB0X5dbBQbAE"
      },
      "source": [
        "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\n",
        "img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "plt.imshow(img/255.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1GYRAjkQa6V"
      },
      "source": [
        "response = requests.get('https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json')\n",
        "imgnet_map = response.json()\n",
        "imgnet_map = {v[1]: k for k, v in imgnet_map.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5vLEHZTQa3Y"
      },
      "source": [
        "img = tf.keras.applications.xception.preprocess_input(img)\n",
        "predictions = model.predict(np.array([img]))\n",
        "decode_predictions(predictions, top=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2crCug0Qa0m"
      },
      "source": [
        "explainer = ExtractActivations()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHvdMoyBRI90"
      },
      "source": [
        "grid = explainer.explain((np.array([img]), None), model, ['block1_conv2_act'])\n",
        "fig, ax = plt.subplots(figsize=(18, 18))\n",
        "ax.imshow(grid, cmap='binary_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c40_qqG2RY1l"
      },
      "source": [
        "grid = explainer.explain((np.array([img]), None), model, ['block2_sepconv2_act'])\n",
        "fig, ax = plt.subplots(figsize=(18, 18))\n",
        "ax.imshow(grid, cmap='binary_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP4q3IzqRo0N"
      },
      "source": [
        "grid = explainer.explain((np.array([img]), None), model, ['block14_sepconv1_act'])\n",
        "fig, ax = plt.subplots(figsize=(18, 18))\n",
        "ax.imshow(grid, cmap='binary_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eBZum2lTWim"
      },
      "source": [
        "# Occlusion Sensitivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QWk4PJPRycN"
      },
      "source": [
        "imgnet_map['Egyptian_cat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyIVi7nPTgPV"
      },
      "source": [
        "from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity\n",
        "\n",
        "explainer = OcclusionSensitivity()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2jsImmxTpBd"
      },
      "source": [
        "img_inp = tf.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\n",
        "img_inp = tf.keras.preprocessing.image.img_to_array(img_inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHgvD-GtT5_U"
      },
      "source": [
        "grid = explainer.explain(([img_inp], None), model, 285, 7)\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "plt.imshow(grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzB_fRxnWJFc"
      },
      "source": [
        "# GradCAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbWUT4vNUrg9"
      },
      "source": [
        "from tf_explain.core.grad_cam import GradCAM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmT0AENwUrZI"
      },
      "source": [
        "explainer = GradCAM()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYQvR_23UUW9"
      },
      "source": [
        "imgnet_map['tabby'], imgnet_map['Egyptian_cat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drQ4MQJJbURE"
      },
      "source": [
        "img_inp = tf.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\n",
        "img_inp = tf.keras.preprocessing.image.img_to_array(img_inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqwQD4HSX5Tb"
      },
      "source": [
        "grid1 = explainer.explain(\n",
        "    validation_data=([img], None),\n",
        "    model=model, layer_name='block1_conv1', class_index=281\n",
        ")\n",
        "grid2 = explainer.explain(\n",
        "    validation_data=([img], None),\n",
        "    model=model, layer_name='block1_conv1', class_index=285\n",
        ")\n",
        "\n",
        "fig = plt.figure(figsize=(18, 8))\n",
        "\n",
        "ax1 = fig.add_subplot(1, 3, 1)\n",
        "ax1.imshow(img_inp / 255.)\n",
        "ax1.imshow(grid1, alpha=0.9)\n",
        "\n",
        "ax2 = fig.add_subplot(1, 3, 2)\n",
        "ax2.imshow(img_inp / 255.)\n",
        "ax2.imshow(grid2, alpha=0.9)\n",
        "\n",
        "ax3 = fig.add_subplot(1, 3, 3)\n",
        "ax3.imshow(img_inp / 255. )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFY-GaQabyTN"
      },
      "source": [
        "grid1 = explainer.explain(\n",
        "    validation_data=([img], None),\n",
        "    model=model, layer_name='block14_sepconv1', class_index=281\n",
        ")\n",
        "grid2 = explainer.explain(\n",
        "    validation_data=([img], None),\n",
        "    model=model, layer_name='block14_sepconv1', class_index=285\n",
        ")\n",
        "\n",
        "fig = plt.figure(figsize=(18, 8))\n",
        "\n",
        "ax1 = fig.add_subplot(1, 3, 1)\n",
        "ax1.imshow(img_inp / 255.)\n",
        "ax1.imshow(grid1, alpha=0.6)\n",
        "\n",
        "ax2 = fig.add_subplot(1, 3, 2)\n",
        "ax2.imshow(img_inp / 255.)\n",
        "ax2.imshow(grid2, alpha=0.6)\n",
        "\n",
        "ax3 = fig.add_subplot(1, 3, 3)\n",
        "ax3.imshow(img_inp / 255. )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltGTATwXbqyL"
      },
      "source": [
        "# Smoothgrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfVqmp-lY8R0"
      },
      "source": [
        "from tf_explain.core.smoothgrad import SmoothGrad\n",
        "\n",
        "explainer = SmoothGrad()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RH0XoH6dKaD"
      },
      "source": [
        "grid1 = explainer.explain(([img], None), model, 281, 80, .2)\n",
        "grid2 = explainer.explain(([img], None), model, 285, 80, .2)\n",
        "\n",
        "fig = plt.figure(figsize=(18, 8))\n",
        "\n",
        "ax1 = fig.add_subplot(1, 3, 1)\n",
        "ax1.imshow(img_inp / 255)\n",
        "ax1.imshow(grid1, alpha=0.9, cmap='binary_r')\n",
        "\n",
        "ax2 = fig.add_subplot(1, 3, 2)\n",
        "ax2.imshow(img_inp / 255)\n",
        "ax2.imshow(grid2, alpha=0.9, cmap=\"binary_r\")\n",
        "\n",
        "ax3 = fig.add_subplot(1, 3, 3)\n",
        "ax3.imshow(img_inp / 255)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWA5_426rUTn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}